# 1. Introduction
This is a project to build a machine translation model using the Transformer model. The model is trained on the English-Vietnamese dataset. The Transformer model is a deep learning model that has been shown to be very effective in machine translation tasks. The model is trained using the PyTorch framework.

# 2. Dataset
The dataset used for training the model is the English-Vietnamese dataset. The dataset contains pairs of English and Vietnamese sentences. The dataset is preprocessed and tokenized before being used for training.

# 3. Model Architecture
The model architecture used for the machine translation model is the Transformer model. The Transformer model is a deep learning model that has been shown to be very effective in machine translation tasks. The model consists of an encoder and a decoder, each of which is made up of multiple layers of self-attention and feedforward neural networks.

# 4. Training
The model is trained using the PyTorch framework. The model is trained on the English-Vietnamese dataset using the Adam optimizer and the cross-entropy loss function. The model is trained for a number of epochs until the loss converges.

# 5. Evaluation
The model is evaluated on a separate test set of English-Vietnamese sentence pairs. The model is evaluated using the BLEU score, which is a metric that measures the quality of machine translation models. The model is also evaluated qualitatively by examining the translations produced by the model.

# 6. Conclusion
In this project, we built a machine translation model using the Transformer model. The model was trained on the English-Vietnamese dataset and evaluated using the BLEU score. The model was shown to be effective in translating English sentences to Vietnamese. The model can be further improved by training on a larger dataset and fine-tuning the hyperparameters.

